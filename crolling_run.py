import os
import sys
import unicodedata
import traceback

import pandas as pd
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException


def get_executable_dir():
    if getattr(sys, 'frozen', False):
        return os.path.abspath(os.path.join(os.path.dirname(sys.executable), "../../../"))
    else:
        return os.path.dirname(os.path.abspath(__file__))

def resource_path(relative_path):
    # .app ì‹¤í–‰ ì‹œ base pathëŠ” Contents/MacOS
    if getattr(sys, 'frozen', False):
        base_path = os.path.abspath(os.path.join(os.path.dirname(sys.executable), "../Resources"))
    else:
        base_path = os.path.dirname(__file__)
    return os.path.join(base_path, relative_path)

# ì´ ê²½ë¡œì— chromedriverê°€ ìœ„ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤
CHROMEDRIVER_PATH = resource_path("resources/chromedriver")


def normalize_url(url: str) -> str:
    return url.replace("http://", "").replace("https://", "").rstrip("/")


log = ""
error_log = ""

try:

    exe_dir = get_executable_dir()
    base_dir = exe_dir
    files_dir = os.path.join(base_dir, "files")
    os.makedirs(files_dir, exist_ok=True)
    logs_dir = os.path.join(base_dir, "logs")
    os.makedirs(files_dir, exist_ok=True)
    
    now_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = os.path.join(logs_dir, f"log_{now_str}.txt")
    err_path = os.path.join(logs_dir, "error_log.txt")

    log += f"[ê²½ë¡œ] base_dir: {base_dir}\n"

    target_fname = unicodedata.normalize("NFC", "ë„¤ì´ë²„_ê²€ìƒ‰ì–´.xlsx")
    excel_path = os.path.join(base_dir, target_fname)
    log += f"ğŸ” ê²€ì‚¬ ì¤‘: {excel_path}\n"
    if not os.path.exists(excel_path):
        raise FileNotFoundError(f"{excel_path} ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    log += "âœ… íŒŒì¼ ë°œê²¬!\n"

    df = pd.read_excel(excel_path)
    log += f"ğŸ“ ì—‘ì…€ ë¡œë”© ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ\n"
    if "í‚¤ì›Œë“œ" not in df.columns or "ë§í¬" not in df.columns:
        raise ValueError("ì—‘ì…€ì— 'í‚¤ì›Œë“œ', 'ë§í¬' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    target_classes = {
        "info_title", "link_tit", "link_question",
        "title_link", "fds-comps-right-image-text-title"
    }
    anchor_selector = ",".join(f"a[class*='{c}']" for c in target_classes)

    #chrome_path = "/Users/david/.wdm/drivers/chromedriver/mac64/138.0.7204.94/chromedriver-mac-arm64/chromedriver"
    options = webdriver.ChromeOptions()
    #options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
 
    service = Service(executable_path=CHROMEDRIVER_PATH)
    driver = webdriver.Chrome(service=service, options=options)

    wait = WebDriverWait(driver, 20)

    results = []
    for idx, row in enumerate(df.itertuples(index=False), start=1):
        keyword = str(row.í‚¤ì›Œë“œ).strip()
        target_url = str(row.ë§í¬).strip()
        log += f"\n[{idx:>2}] âœ… í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì¤‘â€¦\n"

        driver.get("https://www.naver.com")
        wait.until(EC.presence_of_element_located((By.NAME, "query")))
        box = driver.find_element(By.NAME, "query")
        box.clear()
        box.send_keys(keyword)
        box.send_keys(Keys.RETURN)
        time.sleep(random.uniform(10, 12))

        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.api_subject_bx")))
        found = False

        blocks = driver.find_elements(By.CSS_SELECTOR, "div.api_subject_bx")
        log += f"   â–¶ ê·¸ë£¹ ë¸”ë¡ {len(blocks)}ê°œ í™•ì¸\n"

        for b_idx in range(len(blocks)):
            try:
                blocks = driver.find_elements(By.CSS_SELECTOR, "div.api_subject_bx")  # ì¬íƒìƒ‰
                block = blocks[b_idx]

                try:
                    group_title = block.find_element(By.CSS_SELECTOR, "h2.title").text.strip()
                except:
                    try:
                        group_title = block.find_element(By.CSS_SELECTOR, "span.fds-comps-header-headline").text.strip()
                    except:
                        group_title = "ê·¸ë£¹ëª… ì—†ìŒ"
                log += f"   [ê·¸ë£¹{b_idx + 1}] {group_title}\n"

                try:
                    anchors = block.find_elements(By.CSS_SELECTOR, anchor_selector)
                except StaleElementReferenceException:
                    log += f"      Â· StaleElement ë°œìƒ â†’ ì•µì»¤ ì¬íƒìƒ‰ ì‹œë„\n"
                    blocks = driver.find_elements(By.CSS_SELECTOR, "div.api_subject_bx")
                    block = blocks[b_idx]
                    anchors = block.find_elements(By.CSS_SELECTOR, anchor_selector)

                log += f"      Â· ì•µì»¤ {len(anchors)}ê°œ ì¶”ì¶œ\n"

                for rank, a in enumerate(anchors, start=1):
                    href = a.get_attribute("href") or ""
                    text = a.text.strip()
                    log += f"        {rank:>2}. {text} â†’ {href}\n"

                    if normalize_url(target_url) in normalize_url(href):
                        date_candidates = []
                        for sel in [
                            "div.profile_bx span.etc.date",
                            "div.user_info span.sub",
                            "span.etc.date",
                            "span.fds-info-sub-inner-text",
                        ]:
                            try:
                                val = block.find_element(By.CSS_SELECTOR, sel).text.strip()
                                date_candidates.append(val)
                            except:
                                pass
                        date_text = date_candidates[-1].rstrip(".") if date_candidates else "ë“±ë¡ì¼ ì—†ìŒ"
                        log += f"        â†’ ë§¤ì¹­! ìˆœìœ„={rank}, ë“±ë¡ì¼={date_text}\n"

                        results.append({
                            "í‚¤ì›Œë“œ": keyword,
                            "ë§í¬": href,
                            "ê·¸ë£¹ëª…": group_title,
                            "ê¸€ì œëª©": text,
                            "ë“±ë¡ì¼": date_text,
                            "ê¸ˆì¼ ìˆœìœ„": rank,
                        })
                        found = True
                        break

                if found:
                    break

            except Exception as e:
                log += f"   [ê·¸ë£¹{b_idx + 1}] ì˜¤ë¥˜ ë°œìƒ: {e}\n"
                continue

        if not found:
            log += "        â†’ ë§¤ì¹­ëœ ê¸€ ì—†ìŒ\n"
            results.append({
                "í‚¤ì›Œë“œ": keyword,
                "ë§í¬": target_url,
                "ê·¸ë£¹ëª…": "ìˆœìœ„ì— ì—†ìŒ",
                "ê¸€ì œëª©": "ìˆœìœ„ì— ì—†ìŒ",
                "ë“±ë¡ì¼": "ìˆœìœ„ì— ì—†ìŒ",
                "ê¸ˆì¼ ìˆœìœ„": "ìˆœìœ„ì— ì—†ìŒ",
            })

    driver.quit()

    now = datetime.now().strftime("%Y%m%d_%H%M")

    out_path = os.path.join(files_dir, f"ë„¤ì´ë²„_ìˆœìœ„ì²´í¬_í¬ë¡¤ë§_{now}.xlsx")
    pd.DataFrame(results, columns=["í‚¤ì›Œë“œ", "ë§í¬", "ê·¸ë£¹ëª…", "ê¸€ì œëª©", "ë“±ë¡ì¼", "ê¸ˆì¼ ìˆœìœ„"]) \
        .to_excel(out_path, index=False)
    log += f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {out_path}\n"

    #with open(log_path, "w", encoding="utf-8") as f:
    #    f.write(log)
    #print(f"\nğŸ“ ë¡œê·¸ ì €ì¥: {log_path}")

except Exception as e:
    error_log += f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n"
    error_log += traceback.format_exc() + "\n"

    files_dir = os.path.join(get_executable_dir(), "files")
    os.makedirs(files_dir, exist_ok=True)

    now_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    err_path = os.path.join(logs_dir, "error_log.txt")
    with open(err_path, "a", encoding="utf-8") as f:
        f.write(f"\n[{now_str}]\n")
        f.write(error_log)
    print(f"âš ï¸ ì—ëŸ¬ ë¡œê·¸ ê¸°ë¡: {err_path}")

    if sys.platform == "darwin":
        os.system(f"open '{err_path}'")

    sys.exit(1)
